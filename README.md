# ğŸ¤– YuktiAI 
    - Intelligent AI Assistant


<div align="center">

![YuktiAI](https://img.shields.io/badge/YuktiAI-v1.0.0-blue?style=for-the-badge&logo=robot)
![Python](https://img.shields.io/badge/Python-3.8+-green?style=for-the-badge&logo=python)
![Ollama](https://img.shields.io/badge/Ollama-LLaMA_3.2-orange?style=for-the-badge)

**Your Intelligent AI Assistant - No External Redirections**

</div>


## ğŸ¯ Overview

**YuktiAI** is a powerful, standalone AI assistant that provides comprehensive answers across multiple domains without external redirections. Built with **LLaMA 3.2** and **Ollama**, it offers a ChatGPT-like experience that runs entirely offline on your local machine.


## âœ¨ Features

- ğŸ”’ **Complete Privacy** - Runs entirely offline
- ğŸ’¡ **Multi-Domain Expertise** - Coding, business, academics, science
- ğŸ§  **Conversation Memory** - Maintains context across interactions
- ğŸ¨ **Dual Interface** - Streamlit web app + HTML interface
- âš¡ **Fast & Efficient** - Optimized for local deployment
- ğŸš« **No External Dependencies** - Never redirects to other services


## ğŸ› ï¸ Quick Setup

### 1. Install Dependencies
```
pip install streamlit requests python-dotenv
```

### 2. Install Ollama
```
# Visit: https://ollama.com/download
ollama serve
ollama pull llama3.2:3b
```

### 3. Initialize YuktiAI
```
python init.py
```

### 4. Launch Interface
```
# Streamlit Interface
streamlit run app.py

# OR HTML Interface
python server.py
```


## ğŸ“ Project Structure

```
YuktiAI/
â”œâ”€â”€ ğŸ“„ init.py              # Complete system (all components)
â”œâ”€â”€ ğŸ“„ app.py               # Streamlit interface
â”œâ”€â”€ ğŸ“„ server.py            # HTTP server
â”œâ”€â”€ ğŸ“„ index.html           # HTML interface
â”œâ”€â”€ ğŸ“„ script.js            # JavaScript functionality
â”œâ”€â”€ ğŸ“„ style.css            # Styling
â”œâ”€â”€ ğŸ“„ .env                 # Configuration
â”œâ”€â”€ ğŸ“„ requirements.txt     # Dependencies
â””â”€â”€ ğŸ“„ README.md            # This file
```


## ğŸš€ Usage

1. **Start Ollama**: `ollama serve`
2. **Initialize**: Click "Initialize YuktiAI" in the interface
3. **Chat**: Start asking questions across any domain!

### Example Queries
```
ğŸ’» "Write a Python function for sorting algorithms"
ğŸ“š "Explain machine learning in simple terms"
ğŸ” "Compare React vs Vue.js"
ğŸ“ "Create a step-by-step API guide"
```


## ğŸ¨ Interfaces

### Streamlit Interface
- Modern web interface with chat history
- Real-time status indicators
- Settings panel and export functionality

### HTML Interface
- Lightweight web interface
- Direct Ollama API integration
- Mobile-responsive design


## âš™ï¸ Configuration

Edit `.env` file:
```
ASSISTANT_NAME=YuktiAI
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
TEMPERATURE=0.7
MEMORY_SIZE=10
```


## ğŸ› Troubleshooting

| Issue | Solution |
|-------|----------|
| "Ollama not running" | Run `ollama serve` |
| "Model not available" | Run `ollama pull llama3.2:3b` |
| Import errors | Run `python init.py` again |


## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request


## ğŸ“„ License

This project is licensed under the MIT License.


## ğŸ‘¥ Author

**Harsh Raj**

---

<div align="center">

**Made with â¤ï¸ for intelligent conversations**

*Empowering AI without compromising privacy*

</div>
```


The document is concise yet comprehensive, perfect for developers who want to quickly understand and deploy YuktiAI! ğŸš€
